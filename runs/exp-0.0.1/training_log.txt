Step: 0 | epoch: 0 | loss: 3.7334609031677246 | lr: 6.024096385505879e-07
Step: 20 | epoch: 0 | loss: 3.6896893978118896 | lr: 1.2650602409562347e-05
Step: 40 | epoch: 0 | loss: 3.607530117034912 | lr: 2.4698795180574107e-05
Step: 60 | epoch: 0 | loss: 3.531322479248047 | lr: 3.6746987951585866e-05
Step: 80 | epoch: 0 | loss: 3.5299508571624756 | lr: 4.879518072259762e-05
Step: 100 | epoch: 0 | loss: 3.5491809844970703 | lr: 6.0843373493609386e-05
Step: 120 | epoch: 0 | loss: 3.510310411453247 | lr: 7.289156626462113e-05
Step: 140 | epoch: 0 | loss: 3.500704288482666 | lr: 8.493975903563291e-05
Step: 160 | epoch: 0 | loss: 3.4786176681518555 | lr: 9.698795180664466e-05
Step: 166 | epoch: 0 | time_per_epoch: 25.12692618370056 | train_acc: 0.04234880897658027 | avg_loss_per_ep: 3.564289375960109
Step: 166 | epoch: 0 | val_loss: 3.4605102062225344 | val_acc: 0.07714657849914838
Saved ./runs/exp-0.0.1/best.pth with accuracy 0.07714657849914838.
Step: 180 | epoch: 1 | loss: 3.4849302768707275 | lr: 0.00010903614457765641
Step: 200 | epoch: 1 | loss: 3.4266605377197266 | lr: 0.00012108433734866819
Step: 220 | epoch: 1 | loss: 3.370661735534668 | lr: 0.00013313253011967992
Step: 240 | epoch: 1 | loss: 3.3409698009490967 | lr: 0.00014518072289069169
Step: 260 | epoch: 1 | loss: 3.3207573890686035 | lr: 0.00015722891566170345
Step: 280 | epoch: 1 | loss: 3.281926393508911 | lr: 0.00016927710843271524
Step: 300 | epoch: 1 | loss: 3.241405725479126 | lr: 0.00018132530120372697
Step: 320 | epoch: 1 | loss: 3.2158212661743164 | lr: 0.00019337349397473874
Step: 332 | epoch: 1 | time_per_epoch: 24.062358856201172 | train_acc: 0.10462854920264489 | avg_loss_per_ep: 3.329487822141992
Step: 332 | epoch: 1 | val_loss: 2.9398637890815733 | val_acc: 0.22432621981765355
Saved ./runs/exp-0.0.1/best.pth with accuracy 0.22432621981765355.
Step: 340 | epoch: 2 | loss: 3.0942673683166504 | lr: 0.0002054216867457505
Step: 360 | epoch: 2 | loss: 3.02860689163208 | lr: 0.00021746987951676224
Step: 380 | epoch: 2 | loss: 3.002164125442505 | lr: 0.000229518072287774
Step: 400 | epoch: 2 | loss: 2.99839186668396 | lr: 0.00024156626505878576
Step: 420 | epoch: 2 | loss: 2.9129714965820312 | lr: 0.0002536144578297975
Step: 440 | epoch: 2 | loss: 2.91170072555542 | lr: 0.0002656626506008093
Step: 460 | epoch: 2 | loss: 2.7793521881103516 | lr: 0.000277710843371821
Step: 480 | epoch: 2 | loss: 2.7063651084899902 | lr: 0.00028975903614283276
Step: 498 | epoch: 2 | time_per_epoch: 24.53332495689392 | train_acc: 0.22282333250828 | avg_loss_per_ep: 2.923770947628711
Step: 498 | epoch: 2 | val_loss: 2.3607962250709535 | val_acc: 0.42240256487325917
Saved ./runs/exp-0.0.1/best.pth with accuracy 0.42240256487325917.
Step: 500 | epoch: 3 | loss: 2.7034683227539062 | lr: 0.00030180722891384455
Step: 520 | epoch: 3 | loss: 2.726102828979492 | lr: 0.00031385542168485634
Step: 540 | epoch: 3 | loss: 2.6136913299560547 | lr: 0.0003259036144558681
Step: 560 | epoch: 3 | loss: 2.6862032413482666 | lr: 0.00033795180722687987
Step: 580 | epoch: 3 | loss: 2.5753095149993896 | lr: 0.00034999999999789155
Step: 600 | epoch: 3 | loss: 2.6779510974884033 | lr: 0.00036204819276890334
Step: 620 | epoch: 3 | loss: 2.5428571701049805 | lr: 0.00037409638553991513
Step: 640 | epoch: 3 | loss: 2.4057934284210205 | lr: 0.00038614457831092686
Step: 660 | epoch: 3 | loss: 2.469464063644409 | lr: 0.00039819277108193865
Step: 664 | epoch: 3 | time_per_epoch: 25.091572761535645 | train_acc: 0.3359027851443254 | avg_loss_per_ep: 2.5873531289847502
Step: 664 | epoch: 3 | val_loss: 1.9587424337863921 | val_acc: 0.5649734495541529
Saved ./runs/exp-0.0.1/best.pth with accuracy 0.5649734495541529.
Step: 680 | epoch: 4 | loss: 2.418912410736084 | lr: 0.0004102409638529504
Step: 700 | epoch: 4 | loss: 2.297366142272949 | lr: 0.0004222891566239622
Step: 720 | epoch: 4 | loss: 2.4060521125793457 | lr: 0.00043433734939497386
Step: 740 | epoch: 4 | loss: 2.394899368286133 | lr: 0.00044638554216598565
Step: 760 | epoch: 4 | loss: 2.3152730464935303 | lr: 0.00045843373493699744
Step: 780 | epoch: 4 | loss: 2.337124824523926 | lr: 0.0004704819277080092
Step: 800 | epoch: 4 | loss: 2.270026206970215 | lr: 0.00048253012047902097
Step: 820 | epoch: 4 | loss: 2.3721272945404053 | lr: 0.0004945783132500328
Step: 830 | epoch: 4 | time_per_epoch: 25.625466346740723 | train_acc: 0.41311599071225674 | avg_loss_per_ep: 2.361327353730259
Step: 830 | epoch: 4 | val_loss: 1.7290810585021972 | val_acc: 0.6421200280533013
Saved ./runs/exp-0.0.1/best.pth with accuracy 0.6421200280533013.
Step: 840 | epoch: 5 | loss: 2.3624401092529297 | lr: 0.0005066265060210444
Step: 860 | epoch: 5 | loss: 2.2652158737182617 | lr: 0.0005186746987920562
Step: 880 | epoch: 5 | loss: 2.30635142326355 | lr: 0.000530722891563068
Step: 900 | epoch: 5 | loss: 2.1988675594329834 | lr: 0.0005427710843340797
Step: 920 | epoch: 5 | loss: 2.281134605407715 | lr: 0.0005548192771050915
Step: 940 | epoch: 5 | loss: 2.149887800216675 | lr: 0.0005668674698761033
Step: 960 | epoch: 5 | loss: 2.158590078353882 | lr: 0.000578915662647115
Step: 980 | epoch: 5 | loss: 2.0779881477355957 | lr: 0.0005909638554181268
Step: 996 | epoch: 5 | time_per_epoch: 26.08518409729004 | train_acc: 0.4630552903598411 | avg_loss_per_ep: 2.208689392331135
Step: 996 | epoch: 5 | val_loss: 1.5744194746017457 | val_acc: 0.6929165414287145
Saved ./runs/exp-0.0.1/best.pth with accuracy 0.6929165414287145.
Step: 1000 | epoch: 6 | loss: 2.118741989135742 | lr: 0.0006030120481891385
Step: 1020 | epoch: 6 | loss: 2.1489644050598145 | lr: 0.0006150602409601503
Step: 1040 | epoch: 6 | loss: 2.090989589691162 | lr: 0.000627108433731162
Step: 1060 | epoch: 6 | loss: 2.0319442749023438 | lr: 0.0006391566265021738
Step: 1080 | epoch: 6 | loss: 2.169175148010254 | lr: 0.0006512048192731855
Step: 1100 | epoch: 6 | loss: 2.0421652793884277 | lr: 0.0006632530120441973
Step: 1120 | epoch: 6 | loss: 2.017885684967041 | lr: 0.0006753012048152091
Step: 1140 | epoch: 6 | loss: 2.105241298675537 | lr: 0.0006873493975862209
Step: 1160 | epoch: 6 | loss: 1.9659730195999146 | lr: 0.0006993975903572326
Step: 1162 | epoch: 6 | time_per_epoch: 26.24394464492798 | train_acc: 0.501196327334017 | avg_loss_per_ep: 2.1018876677536102
Step: 1162 | epoch: 6 | val_loss: 1.4792050421237946 | val_acc: 0.7264803125939284
Saved ./runs/exp-0.0.1/best.pth with accuracy 0.7264803125939284.
Step: 1180 | epoch: 7 | loss: 2.042691707611084 | lr: 0.0007114457831282443
Step: 1200 | epoch: 7 | loss: 2.052154541015625 | lr: 0.0007234939758992561
Step: 1220 | epoch: 7 | loss: 1.9245121479034424 | lr: 0.0007355421686702679
Step: 1240 | epoch: 7 | loss: 2.069983720779419 | lr: 0.0007475903614412797
Step: 1260 | epoch: 7 | loss: 2.0063557624816895 | lr: 0.0007596385542122915
Step: 1280 | epoch: 7 | loss: 2.074977397918701 | lr: 0.0007716867469833031
Step: 1300 | epoch: 7 | loss: 1.9797463417053223 | lr: 0.0007837349397543149
Step: 1320 | epoch: 7 | loss: 2.0158748626708984 | lr: 0.0007957831325253266
Step: 1328 | epoch: 7 | time_per_epoch: 25.904199361801147 | train_acc: 0.5271737208726707 | avg_loss_per_ep: 2.023791140102478
Step: 1328 | epoch: 7 | val_loss: 1.4037800312042237 | val_acc: 0.756938182546839
Saved ./runs/exp-0.0.1/best.pth with accuracy 0.756938182546839.
Step: 1340 | epoch: 8 | loss: 1.9884858131408691 | lr: 0.0008078313252963384
Step: 1360 | epoch: 8 | loss: 1.9187042713165283 | lr: 0.0008198795180673501
Step: 1380 | epoch: 8 | loss: 1.9989120960235596 | lr: 0.0008319277108383619
Step: 1400 | epoch: 8 | loss: 1.948338270187378 | lr: 0.0008439759036093737
Step: 1420 | epoch: 8 | loss: 2.0937764644622803 | lr: 0.0008560240963803855
Step: 1440 | epoch: 8 | loss: 1.8769183158874512 | lr: 0.0008680722891513973
Step: 1460 | epoch: 8 | loss: 2.0758814811706543 | lr: 0.0008801204819224091
Step: 1480 | epoch: 8 | loss: 1.87589693069458 | lr: 0.0008921686746934207
Step: 1494 | epoch: 8 | time_per_epoch: 26.034855842590332 | train_acc: 0.5523142746013224 | avg_loss_per_ep: 1.9501040534800793
Step: 1494 | epoch: 8 | val_loss: 1.361040461063385 | val_acc: 0.7730688307784791
Saved ./runs/exp-0.0.1/best.pth with accuracy 0.7730688307784791.
Step: 1500 | epoch: 9 | loss: 1.8232346773147583 | lr: 0.0009042168674644325
Step: 1520 | epoch: 9 | loss: 1.9191863536834717 | lr: 0.0009162650602354443
Step: 1540 | epoch: 9 | loss: 1.9424099922180176 | lr: 0.000928313253006456
Step: 1560 | epoch: 9 | loss: 1.8581392765045166 | lr: 0.0009403614457774677
Step: 1580 | epoch: 9 | loss: 1.907421588897705 | lr: 0.0009524096385484795
Step: 1600 | epoch: 9 | loss: 1.920975685119629 | lr: 0.0009644578313194913
Step: 1620 | epoch: 9 | loss: 1.9032385349273682 | lr: 0.0009765060240905031
Step: 1640 | epoch: 9 | loss: 1.8446718454360962 | lr: 0.0009885542168615149
Step: 1660 | epoch: 9 | time_per_epoch: 26.091973781585693 | train_acc: 0.5692750138491095 | avg_loss_per_ep: 1.9035416403448726
Step: 1660 | epoch: 9 | val_loss: 1.3105372846126557 | val_acc: 0.7893998597334937
Saved ./runs/exp-0.0.1/best.pth with accuracy 0.7893998597334937.
Step: 1660 | epoch: 9 | val_loss: 1.3105372846126557 | val_acc: 0.7893998597334937
Saved ./runs/exp-0.0.1/last.pth with accuracy 0.7893998597334937.
Step: 1826 | test_loss_last: 1.372801417654211 | test_acc_last: 0.758836892321672
Step: 1826 | test_loss_best: 1.372801417654211 | test_acc_best: 0.758836892321672
